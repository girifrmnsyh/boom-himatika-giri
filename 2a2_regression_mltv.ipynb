{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748bb4d3",
   "metadata": {},
   "source": [
    "# Init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf1939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import(\n",
    "    mean_absolute_error as MAE,\n",
    "    mean_squared_error as MSE,\n",
    "    mean_absolute_percentage_error as MAPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9066510",
   "metadata": {},
   "source": [
    "# Prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e5316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"./data/trip_data_clean.parquet\")\n",
    "data.info()\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca53420",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc60cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.columns[:-1]\n",
    "target = data.columns[-1]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b35fe",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfecd5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model 1: Random Prediction\n",
    "def random_predict(X):\n",
    "    np.random.seed(42)\n",
    "    return np.random.uniform(low=y.min(), high=y.max(), size=len(X))\n",
    "\n",
    "# Baseline Model 2: Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_train_pred = lr_model.predict(X_train)\n",
    "lr_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Expected Best Model: Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_train_pred = dt_model.predict(X_train)\n",
    "dt_test_pred = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728d1b37",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ff2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(columns=[\"Model\", \"Set_Category\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\"])\n",
    "\n",
    "def evaluate_model(df_metrics, name, dataset, y_true, y_pred):\n",
    "    mae = MAE(y_true, y_pred)\n",
    "    mse = MSE(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = MAPE(y_true, y_pred)\n",
    "\n",
    "    df_metrics.loc[len(df_metrics)] = [name, dataset, mae, mse, rmse, mape]\n",
    "    return df_metrics\n",
    "\n",
    "# Evaluate Random Prediction\n",
    "evaluate_model(df_metrics, \"Random Prediction\", \"Train\", y_train, random_predict(X_train))\n",
    "evaluate_model(df_metrics, \"Random Prediction\", \"Test\", y_test, random_predict(X_test))\n",
    "# Evaluate Linear Regression\n",
    "evaluate_model(df_metrics, \"Linear Regression\", \"Train\", y_train, lr_train_pred)\n",
    "evaluate_model(df_metrics, \"Linear Regression\", \"Test\", y_test, lr_test_pred)\n",
    "# Evaluate Decision Tree Regressor\n",
    "evaluate_model(df_metrics, \"Decision Tree Regressor\", \"Train\", y_train, dt_train_pred)\n",
    "evaluate_model(df_metrics, \"Decision Tree Regressor\", \"Test\", y_test, dt_test_pred)\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3701d9d",
   "metadata": {},
   "source": [
    "## Check Fit Status (Good, Underfit, or Overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed71fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fit_status(df, metric=\"MAE\", threshold=0.1):\n",
    "    \"\"\"\n",
    "    Classify models as Overfit / Underfit / Good fit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns [\"Model\", \"Set_Category\", metric]\n",
    "    metric : str, default=\"RMSE\"\n",
    "        Metric to compare between Train and Test\n",
    "    threshold : float, default=0.2\n",
    "        Relative tolerance (20% by default).\n",
    "        If |Train - Test| > threshold * min(Train, Test), considered misfit.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Original df with an extra column 'Fit_Status'\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "\n",
    "    # Create a column for Fit_Status only for the Test rows\n",
    "    result[\"Fit_Status\"] = None\n",
    "\n",
    "    # Work model by model\n",
    "    for model in result[\"Model\"].unique():\n",
    "        train_row = result[(result.Model == model) & (result.Set_Category == \"Train\")].iloc[0]\n",
    "        test_row = result[(result.Model == model) & (result.Set_Category == \"Test\")].iloc[0]\n",
    "\n",
    "        train_err = train_row[metric]\n",
    "        test_err = test_row[metric]\n",
    "\n",
    "        gap = abs(test_err - train_err)\n",
    "        rel_gap = gap / min(train_err, test_err)\n",
    "\n",
    "        if rel_gap <= threshold:\n",
    "            status = \"Good fit\"\n",
    "        else:\n",
    "            if test_err > train_err:\n",
    "                status = \"Overfit (high test error)\"\n",
    "            else:\n",
    "                status = \"Underfit (high train error)\"  # rare but possible\n",
    "\n",
    "        # Assign status to the test row\n",
    "        idx = result[(result.Model == model) & (result.Set_Category == \"Test\")].index\n",
    "        result.loc[idx, \"Fit_Status\"] = status\n",
    "\n",
    "    return result\n",
    "\n",
    "df_metrics_fit_status = check_fit_status(df_metrics) \n",
    "df_metrics_fit_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11977af9",
   "metadata": {},
   "source": [
    "# Tuning (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f71853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected Best Model: Decision Tree Regressor\n",
    "dt_model_tuned = DecisionTreeRegressor(\n",
    "    random_state=42,\n",
    "    max_depth= 15,\n",
    "    min_samples_leaf=50,\n",
    "\n",
    ")\n",
    "dt_model_tuned.fit(X_train, y_train)\n",
    "dt_tuned_train_pred = dt_model_tuned.predict(X_train)\n",
    "dt_tuned_test_pred = dt_model_tuned.predict(X_test)\n",
    "\n",
    "# Evaluate \n",
    "evaluate_model(df_metrics, \"Decision Tree Regressor (Tuned)\", \"Train\", y_train, dt_tuned_train_pred)\n",
    "evaluate_model(df_metrics, \"Decision Tree Regressor (Tuned)\", \"Test\", y_test, dt_tuned_test_pred)\n",
    "df_metrics_fit_status = check_fit_status(df_metrics) \n",
    "df_metrics_fit_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6639f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metric_result = df_metrics_fit_status[df_metrics_fit_status.Set_Category == \"Test\"]\n",
    "final_metric_result = final_metric_result.sort_values(by=\"MAE\").drop(columns=[\"Set_Category\"]).reset_index(drop=True)\n",
    "final_metric_result.plot(kind=\"barh\", x=\"Model\", y=[\"MAE\"], figsize=(10, 6), title=\"Model Comparison on Test Set\")\n",
    "plt.xlabel(\"MAE\")\n",
    "plt.show()\n",
    "final_metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905cc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=final_metric_result, x=\"MAE\", y=\"Model\", hue=\"Fit_Status\", dodge=False)\n",
    "plt.title(\"Model Comparison on Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better visualization\n",
    "\n",
    "choosen_metric = \"MAE\"\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "ax = sns.barplot(\n",
    "    data=final_metric_result,\n",
    "    x=choosen_metric,\n",
    "    y=\"Model\",\n",
    "    hue=\"Fit_Status\",\n",
    "    dodge=False,\n",
    "    palette=\"Set2\"       \n",
    ")\n",
    "\n",
    "# Add value annotations on bars\n",
    "for i, patch in enumerate(ax.patches):\n",
    "    if i>3:continue\n",
    "    width = patch.get_width()\n",
    "    y = patch.get_y() + patch.get_height() / 2\n",
    "    ax.text(\n",
    "        width + 0.001 * ax.get_xlim()[1], \n",
    "        y,\n",
    "        f\"$ {width:,.2f}\",\n",
    "        va=\"center\",\n",
    "        ha=\"left\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(f\"Prediction Error ({choosen_metric}, $)\", fontsize=12.5)\n",
    "ax.set_ylabel(\"\", fontsize=12)\n",
    "ax.set_title(\"Model Performance\", fontsize=18, fontweight=\"bold\")\n",
    "ax.legend(title=\"Fit Status\", bbox_to_anchor=(.7, 1), loc=\"upper left\", fontsize=10, title_fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boom-himatika-its",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
